
dev: False #if in dev mode, do not save output, etc.


##############
# Experiment #
##############
n_iterations: 3
save_every: 1
grid_size: [3, 3]


##############
# Model - General #
##############
name: "belief"
parameters:
  personas: ["believer", "nonbeliever"]
  perception_radius: 1
  update_likelihood: 0.5
  early_stopping: True # if probability update, may not stop



##############
# LLM Model#
##############
model_class_llm: "BeliefLLMModel"
parameters_llm:
  llm_name: "ollama_llama2"
  ratio: [0.3, 0.5]  # #ratio believing in  #TODO: change to ratio of each persona
  temperature: 0.8
  top_p: 0.95
  max_tokens: 1000
  recent_memory: False #if use recent memory
  external_memory: False #if use external memory



##############
# ABM Model#
##############
#similarity threshold is a list
model_class_abm: "BeliefABMModel"
parameters_abm:  #TODO: Rather than threshold could choose likelihood of moving
  ratio: [0.3, 0.5] #ratio believing in  #TODO: change to ratio of each persona
  recent_memory: False #if use recent memory
  external_memory: False #if use external memory

##############
# GPT #
##############
llm_model:
  llama2: "llama-2-7b-chat.ggmlv3.q8_0"
  gpt3: "gpt-3.5-turbo" #"gpt-3.5-turbo" 
  gpt4: "gpt-4" #"gpt-3.5-turbo" 

max_tokens:
  llama-2-7b-chat.ggmlv3.q8_0: 4000
  gpt-3.5-turbo: 4000
  gpt-4: 8000



